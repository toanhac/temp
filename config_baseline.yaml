seed_everything: 7
trainer:
  checkpoint_callback: true
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 1
        monitor: val_ExpRate
        mode: max
        filename: '{epoch}-{step}-{val_ExpRate:.4f}'
  gpus: 1
  check_val_every_n_epoch: 2
  max_epochs: 300
  deterministic: true

model:
  d_model: 256
  growth_rate: 24
  num_layers: 16
  fusion_out_channels: 128
  
  nhead: 8
  num_decoder_layers: 3
  dim_feedforward: 1024
  dropout: 0.3
  
  dc: 32
  cross_coverage: true
  self_coverage: true
  
  # DISABLE guided coverage to test if it's the problem
  use_spatial_aux: false
  use_relation_aux: false
  spatial_hidden_channels: 128
  relation_hidden_channels: 128
  spatial_loss_weight: 0.0
  relation_loss_weight: 0.0
  
  use_guided_coverage: false
  dynamic_weighting: false
  alpha_spatial: 0.0
  alpha_relation: 0.0
  decay_tau_ratio: 3.0
  coverage_aware_w1: 2.0
  coverage_aware_w2: 1.0
  
  beam_size: 10
  max_len: 200
  alpha: 1.0
  early_stopping: false
  temperature: 1.0
  
  learning_rate: 0.005
  patience: 20

data:
  zipfile_path: data.zip
  test_year: 2014
  train_batch_size: 8
  eval_batch_size: 4
  num_workers: 8
  scale_aug: true
  use_spatial_maps: false
  use_relation_maps: false
  gt_cache_dir: data/cached_maps
  generate_spatial_on_fly: false
